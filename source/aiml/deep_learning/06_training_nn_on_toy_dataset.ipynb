{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the NN on a toy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a neural network on a toy dataset using PyTorch, we'll follow these steps:\n",
    "\n",
    "1. Prepare a toy dataset.\n",
    "2. Define the neural network architecture.\n",
    "3. Specify the loss function and optimizer.\n",
    "4. Iterate over the dataset in mini-batches, performing forward and backward passes.\n",
    "5. Monitor training progress and evaluate the model.\n",
    "\n",
    "Let's create a simple example where we generate a toy dataset and train a feedforward neural network to classify it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare a Toy Dataset\n",
    "\n",
    "For simplicity, let's create a toy dataset with random features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "        self.X = torch.randn(num_samples, 2)  # Two-dimensional features\n",
    "        self.y = torch.randint(0, 2, (num_samples,))  # Binary labels (0 or 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create the toy dataset\n",
    "toy_dataset = ToyDataset(num_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the Neural Network Architecture\n",
    "\n",
    "Let's define a simple feedforward neural network architecture for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Specify the Loss Function and Optimizer\n",
    "\n",
    "Let's use binary cross-entropy loss and stochastic gradient descent (SGD) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the Model\n",
    "\n",
    "Iterate over the dataset in mini-batches, performing forward and backward passes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_epochs = 100\n",
    "batch_size = 10\n",
    "dataloader = DataLoader(toy_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Model\n",
    "\n",
    "You can evaluate the trained model on a validation set or test set to assess its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.00%\n"
     ]
    }
   ],
   "source": [
    "# Example evaluation on the entire dataset\n",
    "with torch.no_grad():\n",
    "    outputs = model(toy_dataset.X)\n",
    "    predicted = (outputs > 0.5).squeeze().int()\n",
    "    accuracy = (predicted == toy_dataset.y).float().mean()\n",
    "    print(f'Accuracy: {accuracy.item()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Conclusion\n",
    "\n",
    "In this example, we trained a simple feedforward neural network on a toy dataset for binary classification using PyTorch. You can customize the dataset, neural network architecture, loss function, optimizer, and training parameters based on your specific task and dataset. Experiment with different configurations to improve the performance of your neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
