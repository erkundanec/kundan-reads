{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation methods are techniques used to fill in missing data in datasets, ensuring that analyses remain robust and accurate. Here's an overview of various imputation methods. Python code examples for each of the imputation methods using popular libraries like `pandas`, `sklearn`, `fancyimpute`, and `statsmodels` are given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Imputation Methods\n",
    "  These methods are straightforward and assume the missing data can be approximated by basic statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Imputation\n",
    "Replaces missing values with the mean of the observed values for a variable.\n",
    "\n",
    "**Example**: \n",
    "\n",
    "Suppose you have a dataset of test scores for a class of students, but one student’s score is missing.\n",
    "\n",
    "- Dataset: `[85, 90, 78, NaN, 88]`\n",
    "- Imputation: The mean score is `(85 + 90 + 78 + 88) / 4 = 85.25`\n",
    "- Imputed Dataset: `[85, 90, 78, 85.25, 88]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   score\n",
      "0  85.00\n",
      "1  90.00\n",
      "2  78.00\n",
      "3  85.25\n",
      "4  88.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'score': [85, 90, 78, np.nan, 88]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing values with mean\n",
    "df['score'].fillna(df['score'].mean(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Imputation\n",
    "Uses the median instead of the mean, useful for skewed distributions.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "You have a dataset of household incomes, but one income is missing.\n",
    "\n",
    "- Dataset: `[45000, 52000, 60000, NaN, 75000]`\n",
    "- Imputation: The median income is `56000` (the middle value).\n",
    "- Imputed Dataset: `[45000, 52000, 60000, 56000, 75000]`\n",
    "\n",
    "\n",
    "**Explanation**\n",
    "\n",
    "When you calculate the **median**, it’s essential to **consider all the non-missing values** (excluding `np.nan`), and then find the middle value of the sorted list.\n",
    "\n",
    "1. Remove the missing value (`np.nan`) and sort the remaining values:\n",
    "   ```\n",
    "   [45000, 52000, 60000, 75000]\n",
    "   ```\n",
    "\n",
    "2. Calculate the median:\n",
    "   - For an **even** number of values (4 values in this case), the median is the **average** of the two middle numbers.\n",
    "   - The middle values are `52000` and `60000`.\n",
    "   - So, the median is:\n",
    "     $$\n",
    "     \\text{Median} = \\frac{52000 + 60000}{2} = \\frac{112000}{2} = 56000\n",
    "     $$\n",
    "\n",
    "Thus, when you run `df['income'].median()`, the result is `56000`, not `60000`.\n",
    "\n",
    "**Updated DataFrame:**\n",
    "After imputing the missing value with the median `56000`, your DataFrame will look like this:\n",
    "\n",
    "```\n",
    "   income\n",
    "0  45000.0\n",
    "1  52000.0\n",
    "2  60000.0\n",
    "3  56000.0\n",
    "4  75000.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    income\n",
      "0  45000.0\n",
      "1  52000.0\n",
      "2  60000.0\n",
      "3  56000.0\n",
      "4  75000.0\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataset\n",
    "data = {'income': [45000, 52000, 60000, np.nan, 75000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing values with median\n",
    "df['income'].fillna(df['income'].median(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode Imputation\n",
    "Fills missing values with the mode, commonly used for categorical data.\n",
    "\n",
    "**Example**\n",
    "\n",
    "You have a dataset of customer preferences, but one preference is missing.\n",
    "\n",
    "- Dataset: `['Red', 'Blue', 'Red', 'Green', NaN]`\n",
    "- Imputation: The mode (most frequent) value is 'Red'.\n",
    "- Imputed Dataset: `['Red', 'Blue', 'Red', 'Green', 'Red']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color\n",
      "0    Red\n",
      "1   Blue\n",
      "2    Red\n",
      "3  Green\n",
      "4    Red\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values with mode (for categorical data)\n",
    "data = {'color': ['Red', 'Blue', 'Red', 'Green', np.nan]}\n",
    "df = pd.DataFrame(data)\n",
    "df['color'].fillna(df['color'].mode()[0], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Imputation\n",
    "Assigns a predefined constant (e.g., 0 or -1) to missing values.\n",
    "\n",
    "**Example**\n",
    "\n",
    "A survey includes a question on age, but one response is missing. You decide to impute with a constant value of `0` (assuming the person skipped that question).\n",
    "\n",
    "- Dataset: `[25, 30, NaN, 22, 28]`\n",
    "- Imputation: Replace `NaN` with `0`.\n",
    "- Imputed Dataset: `[25, 30, 0, 22, 28]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   score\n",
      "0   85.0\n",
      "1   90.0\n",
      "2   78.0\n",
      "3    0.0\n",
      "4   88.0\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataset\n",
    "data = {'score': [85, 90, 78, np.nan, 88]}\n",
    "df = pd.DataFrame(data)\n",
    "# Impute missing values with a constant value\n",
    "df['score'].fillna(0, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Statistical Imputation Methods\n",
    "   These methods consider relationships between variables for more accurate imputations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Imputation\n",
    "Predicts missing values using a regression model based on other variables.\n",
    "     \n",
    "- **Example**: You have a dataset where one feature is missing, but it's correlated with another feature.\n",
    "- Dataset: `[Height (cm), Weight (kg)]`\n",
    "- Suppose you know that `Weight` can be predicted based on `Height` (e.g., through a linear regression model `Weight = 0.5 * Height + 10`). If `Weight` is missing for `Height = 170 cm`, use the regression to impute it.\n",
    "- **Imputation**: `Weight = 0.5 * 170 + 10 = 95 kg`\n",
    "- **Imputed Dataset**: `[170, 95]` for the missing `Weight` value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Imputation\n",
    "\n",
    "Used for categorical data where the missing values are predicted with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Imputation\n",
    "Replaces missing values by averaging or taking the mode of the nearest neighbors based on distance metrics.\n",
    "\n",
    "- **Example**: You have a dataset of patients with missing values for their cholesterol levels. The missing value is imputed by finding the nearest neighbors (patients with similar characteristics, like age and weight) and averaging their cholesterol levels.\n",
    "- Dataset: `[Age, Weight, Cholesterol]`\n",
    "- For a patient with missing cholesterol data, the algorithm looks for the closest patients in terms of age and weight and takes the average cholesterol level of those patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Imputation by Chained Equations (MICE)\n",
    "\n",
    "Iteratively imputes missing data using a set of regression models for each variable with missing data.\n",
    "\n",
    "- **Example**: You have a dataset with missing values across several variables (e.g., `Income`, `Education`, `Age`).\n",
    "- MICE will impute each missing value using a regression model that accounts for other variables. It repeats this process multiple times until convergence is reached.\n",
    "- The imputed values depend on the relationships between all variables, which results in more accurate estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Machine Learning-Based Imputation\n",
    "   These methods leverage machine learning models for more sophisticated imputations.\n",
    "\n",
    "   - **Random Forest Imputation**: Uses random forests to predict missing values based on other data in the dataset.\n",
    "   - **Gradient Boosting Machines (GBM) Imputation**: Similar to random forests but uses boosting algorithms for prediction.\n",
    "   - **Deep Learning Imputation**: Neural networks can be trained to predict missing values, especially in complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Imputation\n",
    "   Instead of filling in a single value, multiple imputation generates several possible datasets by imputing values multiple times and then combines the results.\n",
    "\n",
    "   - **Rubin’s Multiple Imputation**: Imputes missing data multiple times, runs analyses on each complete dataset, and pools the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time-Series Specific Imputation \n",
    "   For time-series data, the following methods are often used:\n",
    "\n",
    "   - **Last Observation Carried Forward (LOCF)**: Replaces missing values with the last observed value.\n",
    "   - **Next Observation Carried Backward (NOCB)**: Uses the next available observation.\n",
    "   - **Interpolation**: Estimates missing values based on linear, spline, or polynomial interpolation.\n",
    "   - **Seasonal Decomposition of Time Series (STL) Imputation**: Decomposes the time series and imputes based on the trend, seasonality, and residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Probabilistic Imputation Methods \n",
    "   These methods use probability distributions to estimate missing values.\n",
    "\n",
    "   - **Expectation-Maximization (EM) Algorithm**: Estimates missing data by iteratively updating the expected value.\n",
    "   - **Bayesian Imputation**: Draws imputations from a posterior distribution based on prior knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Domain-Specific Imputation \n",
    "   In certain domains, imputation is tailored to the data’s characteristics:\n",
    "\n",
    "   - **Genetic Data Imputation**: Uses linkage disequilibrium patterns to predict missing genotypes.\n",
    "   - **Spatial Data Imputation**: Employs geostatistical techniques like Kriging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Right Method  \n",
    "   - **Simple imputation** works for small datasets with limited missingness.\n",
    "   - **Advanced and ML-based methods** are suitable for larger, complex datasets where relationships between variables are crucial.\n",
    "   - **Time-series methods** work well when data is sequential.\n",
    "   - **Multiple imputation** is recommended when preserving variability and uncertainty is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Machine Learning-Based Imputation**\n",
    "\n",
    "   - **Random Forest Imputation**\n",
    "     - **Example**: In a dataset of customer information, some values for `Annual Income` are missing, but other columns like `Age`, `Occupation`, and `Location` are available.\n",
    "     - A random forest model is trained using these features to predict the missing `Income` values.\n",
    "     - **Imputed Dataset**: The model predicts and imputes the missing values based on the relationships it learns from other customer data.\n",
    "\n",
    "   - **Gradient Boosting Machines (GBM) Imputation**\n",
    "     - **Example**: Similar to random forest, but this time a gradient boosting algorithm (like XGBoost or LightGBM) is used to predict the missing `Annual Income` based on other variables (e.g., `Age`, `Gender`, `Occupation`).\n",
    "     - The model builds several trees and combines their predictions to impute the missing income values.\n",
    "\n",
    "   - **Deep Learning Imputation**\n",
    "     - **Example**: You have a complex dataset of medical records with missing values. A neural network (e.g., an autoencoder) is trained to predict missing values based on the patterns it learns from the observed data.\n",
    "     - The autoencoder compresses the dataset into a lower-dimensional space and reconstructs it, filling in missing values during this process.\n",
    "\n",
    "### 4. **Multiple Imputation**\n",
    "\n",
    "   - **Rubin’s Multiple Imputation**\n",
    "     - **Example**: In a clinical trial, data on patients’ blood pressure is missing for some individuals. Instead of imputing a single value, multiple imputations are performed (e.g., 5 datasets), each with different plausible values for the missing data. The analysis is performed on all 5 datasets, and the results are combined to account for the uncertainty in the imputations.\n",
    "     - **Imputed Datasets**: 5 datasets are created with different values for the missing blood pressure data.\n",
    "\n",
    "### 5. **Time-Series Specific Imputation**\n",
    "\n",
    "   - **Last Observation Carried Forward (LOCF)**\n",
    "     - **Example**: In a time-series dataset of daily sales, if a data point is missing for a specific day, it can be imputed by carrying forward the last observed sales value.\n",
    "     - **Imputed Dataset**: If sales on day 4 are missing, then the value from day 3 is used to fill the gap.\n",
    "\n",
    "   - **Interpolation**\n",
    "     - **Example**: You have monthly temperature data, and one month's data is missing. You can use linear interpolation to estimate the missing value based on the values from the adjacent months.\n",
    "     - **Imputed Dataset**: If the temperatures for January and March are known, the missing temperature for February can be interpolated as the average of January and March temperatures.\n",
    "\n",
    "   - **Seasonal Decomposition of Time Series (STL) Imputation**\n",
    "     - **Example**: For a monthly sales dataset with a seasonal pattern, STL decomposition can separate the trend, seasonality, and residuals. Missing values are then imputed based on the seasonal and trend components.\n",
    "     - **Imputed Dataset**: The missing data is imputed based on the seasonal and trend components of the decomposition.\n",
    "\n",
    "### 6. **Probabilistic Imputation Methods**\n",
    "\n",
    "   - **Expectation-Maximization (EM) Algorithm**\n",
    "     - **Example**: In a dataset where income is missing, the EM algorithm estimates missing values by iterating between two steps: the expectation step (estimating missing values given the observed data) and the maximization step (estimating model parameters).\n",
    "     - The EM algorithm gradually fills in missing data with the most likely values based on the distribution of the observed data.\n",
    "\n",
    "   - **Bayesian Imputation**\n",
    "     - **Example**: In a dataset with missing values for a feature like `Age`, Bayesian imputation would estimate missing values based on the posterior distribution, incorporating prior beliefs about the distribution of age.\n",
    "     - **Imputed Dataset**: Missing `Age` values are filled with estimates drawn from the posterior distribution.\n",
    "\n",
    "### 7. **Domain-Specific Imputation**\n",
    "\n",
    "   - **Genetic Data Imputation**\n",
    "     - **Example**: In a genetic study, missing genotypic data (like SNPs) can be imputed using information from a reference panel that provides probabilistic estimates of the missing genotypes based on linkage disequilibrium.\n",
    "     - **Imputed Dataset**: Missing SNP values are imputed based on patterns of genetic variation in the population.\n",
    "\n",
    "   - **Spatial Data Imputation (Kriging)**\n",
    "     - **Example**: For environmental data, if a few sensor locations are missing temperature readings, Kriging (a geostatistical method) can be used to interpolate values at those missing locations based on surrounding sensor data.\n",
    "     - **Imputed Dataset**: Missing temperature values are imputed using nearby measurements, with a spatial correlation model.\n",
    "\n",
    "### Summary  \n",
    "Each method has its strengths and is suited to different types of missing data. Simple methods work well when the data is missing at random, while more complex models are better for capturing intricate patterns and relationships in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. **Simple Imputation Methods**\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Advanced Statistical Imputation Methods**\n",
    "\n",
    "#### **Linear Regression Imputation**\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'Height': [150, 160, 170, 180, 190],\n",
    "        'Weight': [50, 60, np.nan, 80, 90]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Prepare the data for imputation (remove missing value rows for regression model)\n",
    "train_data = df.dropna()\n",
    "\n",
    "# Train a linear regression model to predict missing values\n",
    "model = LinearRegression()\n",
    "model.fit(train_data[['Height']], train_data['Weight'])\n",
    "\n",
    "# Predict missing values for 'Weight'\n",
    "missing_height = df[df['Weight'].isna()]['Height']\n",
    "predicted_weight = model.predict(missing_height.values.reshape(-1, 1))\n",
    "\n",
    "# Impute missing values\n",
    "df.loc[df['Weight'].isna(), 'Weight'] = predicted_weight\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### **K-Nearest Neighbors (KNN) Imputation**\n",
    "\n",
    "```python\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Create a sample dataset with missing values\n",
    "data = {'Height': [150, 160, 170, np.nan, 190],\n",
    "        'Weight': [50, 60, np.nan, 80, 90]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# KNN Imputer\n",
    "knn = KNNImputer(n_neighbors=2)\n",
    "df_imputed = knn.fit_transform(df)\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=df.columns)\n",
    "\n",
    "print(df_imputed)\n",
    "```\n",
    "\n",
    "#### **Multivariate Imputation by Chained Equations (MICE)**\n",
    "\n",
    "```python\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'Height': [150, 160, 170, np.nan, 190],\n",
    "        'Weight': [50, 60, np.nan, 80, 90]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# MICE Imputation\n",
    "mice = IterativeImputer(max_iter=10, random_state=0)\n",
    "df_imputed = mice.fit_transform(df)\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=df.columns)\n",
    "\n",
    "print(df_imputed)\n",
    "```\n",
    "\n",
    "### 3. **Machine Learning-Based Imputation**\n",
    "\n",
    "#### **Random Forest Imputation**\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'Height': [150, 160, 170, 180, 190],\n",
    "        'Weight': [50, 60, np.nan, 80, 90]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Prepare the data for imputation (remove missing value rows for training)\n",
    "train_data = df.dropna()\n",
    "\n",
    "# Train a random forest model\n",
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(train_data[['Height']], train_data['Weight'])\n",
    "\n",
    "# Predict missing values for 'Weight'\n",
    "missing_height = df[df['Weight'].isna()]['Height']\n",
    "predicted_weight_rf = model_rf.predict(missing_height.values.reshape(-1, 1))\n",
    "\n",
    "# Impute missing values\n",
    "df.loc[df['Weight'].isna(), 'Weight'] = predicted_weight_rf\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### **Gradient Boosting Machines (GBM) Imputation**\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'Height': [150, 160, 170, 180, 190],\n",
    "        'Weight': [50, 60, np.nan, 80, 90]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Prepare the data for imputation (remove missing value rows for training)\n",
    "train_data = df.dropna()\n",
    "\n",
    "# Train a gradient boosting model\n",
    "model_gbm = GradientBoostingRegressor()\n",
    "model_gbm.fit(train_data[['Height']], train_data['Weight'])\n",
    "\n",
    "# Predict missing values for 'Weight'\n",
    "missing_height = df[df['Weight'].isna()]['Height']\n",
    "predicted_weight_gbm = model_gbm.predict(missing_height.values.reshape(-1, 1))\n",
    "\n",
    "# Impute missing values\n",
    "df.loc[df['Weight'].isna(), 'Weight'] = predicted_weight_gbm\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### **Deep Learning Imputation (Autoencoder)**\n",
    "\n",
    "```python\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'Height': [150, 160, 170, 180, 190],\n",
    "        'Weight': [50, 60, np.nan, 80, 90]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Prepare the data for imputation (remove missing value rows for training)\n",
    "train_data = df.dropna()\n",
    "\n",
    "# Train a simple neural network for imputation (MLP Regressor)\n",
    "model_nn = MLPRegressor(hidden_layer_sizes=(5,), max_iter=1000)\n",
    "model_nn.fit(train_data[['Height']], train_data['Weight'])\n",
    "\n",
    "# Predict missing values for 'Weight'\n",
    "missing_height = df[df['Weight'].isna()]['Height']\n",
    "predicted_weight_nn = model_nn.predict(missing_height.values.reshape(-1, 1))\n",
    "\n",
    "# Impute missing values\n",
    "df.loc[df['Weight'].isna(), 'Weight'] = predicted_weight_nn\n",
    "print(df)\n",
    "```\n",
    "\n",
    "### 4. **Multiple Imputation**\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'Height': [150, 160, 170, np.nan, 190],\n",
    "        'Weight': [50, 60, np.nan, 80, 90]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use the Multiple Imputation package (MICE) from Statsmodels\n",
    "imp = sm.imputation.MICEData(df)\n",
    "df_imputed = imp.data\n",
    "\n",
    "print(df_imputed)\n",
    "```\n",
    "\n",
    "### 5. **Time-Series Specific Imputation**\n",
    "\n",
    "#### **Last Observation Carried Forward (LOCF)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a time-series dataset\n",
    "data = {'date': pd.date_range(start='2024-01-01', periods=5, freq='D'),\n",
    "        'sales': [200, 210, np.nan, 250, np.nan]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing sales values by carrying forward the last observation\n",
    "df['sales'].fillna(method='ffill', inplace=True)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### **Interpolation (Linear Interpolation)**\n",
    "\n",
    "```python\n",
    "# Impute missing values using linear interpolation\n",
    "df['sales'] = df['sales'].interpolate(method='linear')\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### **Seasonal Decomposition of Time Series (STL)**\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample time-series data with missing values\n",
    "data = {'date': pd.date_range(start='2024-01-01', periods=10, freq='D'),\n",
    "        'sales': [200, 210, np.nan, 250, np.nan, 230, np.nan, 260, 270, 280]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform STL decomposition and interpolate missing values\n",
    "df.set_index('date', inplace=True)\n",
    "decomposition = STL(df['sales'], seasonal=7)\n",
    "result = decomposition.fit()\n",
    "\n",
    "# Interpolate the missing values using the trend and seasonal components\n",
    "df['sales'] = result.trend + result.seasonal + result.resid\n",
    "print(df)\n",
    "```\n",
    "\n",
    "### 6. **Probabilistic Imputation Methods**\n",
    "\n",
    "#### **Expectation-Maximization (EM) Algorithm**\n",
    "\n",
    "```python\n",
    "from statsmodels.imputation import mice\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'Height': [150, 160, 170, np.nan, 190],\n",
    "        'Weight': [50, 60, np.nan, 80, 90]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use MICE to perform expectation-maximization imputation\n",
    "imp = mice.MICEData(df)\n",
    "df_imputed = imp.data\n",
    "print(df_imputed)\n",
    "```\n",
    "\n",
    "These examples should help you get started with different imputation methods in Python. Depending on your data type (numeric, categorical, time-series, etc.), you can choose the method that best suits your needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
