{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle outliers in Financial Ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling outliers in financial ratios (or any financial data) is crucial because they can distort statistical models, impact visualizations, and lead to misleading conclusions. The best approach depends on the nature of the data and the specific financial ratios you're dealing with. Below are some recommended techniques, considering the type of financial data typically found in `industry_df`.\n",
    "\n",
    "## **Common Financial Ratios:**\n",
    "- **P/E Ratio (Price-to-Earnings)**: Can have extreme values, especially for companies with low or negative earnings.\n",
    "- **P/B Ratio (Price-to-Book)**: Extreme values can be due to undervaluation or overvaluation.\n",
    "- **ROE (Return on Equity)**: Outliers can occur due to non-recurring items or extreme financial performance.\n",
    "- **Debt-to-Equity Ratio**: Can be highly skewed, especially for companies in capital-intensive industries.\n",
    "\n",
    "## **Approaches to Handle Outliers in Financial Data:**\n",
    "\n",
    "### **1. Identify and Visualize Outliers**\n",
    "\n",
    "Before deciding on a method, it's important to **visualize** and **quantify** the outliers.\n",
    "\n",
    "**Visualization:**\n",
    "- **Box plots**: Box plots give a quick view of the distribution and potential outliers.\n",
    "- **Histograms**: Histograms can reveal the shape of the distribution and highlight the presence of extreme values.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "industry_df.boxplot(figsize=(12, 8))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Boxplot for Financial Ratios\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **2. Statistical Methods to Detect Outliers**\n",
    "\n",
    "You can use statistical methods to **quantify** and **filter outliers**.\n",
    "\n",
    "**a. Z-Score Method (Standardized Method)**:\n",
    "- This method is suitable when data follows a **normal distribution**.\n",
    "- **Z-score** measures how far away a value is from the mean in terms of standard deviations.\n",
    "  \n",
    "   **Code Example**:\n",
    "   ```python\n",
    "   from scipy.stats import zscore\n",
    "\n",
    "   # Calculate Z-scores for the selected financial ratios\n",
    "   z_scores = industry_df[VALUE_METRICS].apply(zscore)\n",
    "   \n",
    "   # Filter out data points with absolute Z-score greater than a threshold (e.g., 3)\n",
    "   industry_df_no_outliers = industry_df[(z_scores < 3).all(axis=1)]\n",
    "   ```\n",
    "\n",
    "   - **Threshold**: A Z-score greater than **3** or less than **-3** typically indicates an outlier.\n",
    "\n",
    "**b. IQR (Interquartile Range) Method**:\n",
    "- The IQR is more robust and works better when data is **skewed** or **not normally distributed**.\n",
    "- Values outside the **1.5 times IQR** (below Q1 - 1.5*IQR or above Q3 + 1.5*IQR) are typically considered outliers.\n",
    "\n",
    "   **Code Example**:\n",
    "   ```python\n",
    "   Q1 = industry_df[VALUE_METRICS].quantile(0.25)\n",
    "   Q3 = industry_df[VALUE_METRICS].quantile(0.75)\n",
    "   IQR = Q3 - Q1\n",
    "\n",
    "   # Filter out outliers\n",
    "   industry_df_no_outliers = industry_df[~((industry_df[VALUE_METRICS] < (Q1 - 1.5 * IQR)) | \n",
    "                                            (industry_df[VALUE_METRICS] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "   ```\n",
    "\n",
    "   - **Effect**: This approach is more robust for non-normal data and works well for financial ratios, which are often skewed.\n",
    "\n",
    "### **3. Treating Outliers (After Detection)**\n",
    "\n",
    "Once outliers are identified, there are several ways to handle them:\n",
    "\n",
    "**a. Remove Outliers:**\n",
    "- If the number of outliers is small and they are likely errors or irrelevant, **removing** them is a reasonable approach.\n",
    "\n",
    "   ```python\n",
    "   # Remove rows containing outliers (using IQR method as example)\n",
    "   industry_df_cleaned = industry_df_no_outliers\n",
    "   ```\n",
    "\n",
    "**b. Cap or Clip Outliers:**\n",
    "- If the outliers are extreme but not errors (e.g., high P/E ratios), **capping** the values can be effective. Capping replaces values that exceed a certain threshold with the threshold value.\n",
    "\n",
    "   ```python\n",
    "   # Cap values to the 95th percentile\n",
    "   upper_cap = industry_df[VALUE_METRICS].quantile(0.95)\n",
    "   lower_cap = industry_df[VALUE_METRICS].quantile(0.05)\n",
    "\n",
    "   industry_df_clipped = industry_df[VALUE_METRICS].apply(lambda x: x.clip(lower=lower_cap, upper=upper_cap))\n",
    "   ```\n",
    "\n",
    "   - **Effect**: Caps the extreme values at the given percentiles to prevent them from distorting analysis.\n",
    "\n",
    "**c. Impute Outliers:**\n",
    "- If the outliers are deemed valid but extreme, **imputing** them with more representative values like the **median** or **mean** might be appropriate.\n",
    "\n",
    "   ```python\n",
    "   # Impute outliers with the median for each column\n",
    "   industry_df_imputed = industry_df[VALUE_METRICS].apply(lambda x: x.fillna(x.median()))\n",
    "   ```\n",
    "\n",
    "   - **Effect**: Replaces extreme outliers with a more central value, making them less influential in model training.\n",
    "\n",
    "### **4. Log Transformation (for Skewed Data)**\n",
    "If your financial data is **positively skewed**, applying a **log transformation** can help reduce the impact of extreme values.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Apply log transformation to reduce skew\n",
    "industry_df_transformed = industry_df[VALUE_METRICS].apply(lambda x: np.log1p(x))  # log(1 + x)\n",
    "```\n",
    "\n",
    "- **Effect**: Log transformation reduces the impact of large values, which can be particularly useful for financial ratios like P/E or P/B.\n",
    "\n",
    "### **5. Robust Scaling (For Outliers and Skewness)**\n",
    "If you have **outliers** and **skewness**, using **RobustScaler** is a good approach. It scales features using the **median and interquartile range** (IQR), making it less sensitive to outliers.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "industry_df_scaled = pd.DataFrame(scaler.fit_transform(industry_df[VALUE_METRICS]), columns=VALUE_METRICS)\n",
    "```\n",
    "\n",
    "- **Effect**: Scales data while minimizing the influence of outliers.\n",
    "\n",
    "---\n",
    "\n",
    "## **Best Approach for Financial Ratios**:\n",
    "- **For data with skewness** (like P/E, P/B ratios), **log transformation** or **Box-Cox transformation** can help reduce extreme skewness.\n",
    "- **For non-normal data** with extreme outliers, using **IQR filtering** or **RobustScaler** is often the best approach.\n",
    "- **Imputation** of outliers with the median is another viable approach if outliers are valid but need to be controlled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling outliers for target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling outliers in the **target variable** (dependent variable) requires careful consideration because removing or transforming outliers can impact the predictive model's performance and accuracy. The strategy depends on whether the outliers are genuine data points or errors and the nature of the analysis.\n",
    "\n",
    "Here are some recommended approaches for handling outliers in the target variable:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Identify Outliers in the Target Variable**\n",
    "Before handling outliers, it's essential to identify them. Visualization and statistical methods can help.\n",
    "\n",
    "#### **Visualization Techniques**:\n",
    "- **Boxplot**: Displays potential outliers visually.\n",
    "- **Histogram**: Shows the distribution and any extreme values.\n",
    "- **Scatter Plot**: Useful if you want to examine the target variable against predictors.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Boxplot to visualize outliers\n",
    "plt.figure(figsize=(8, 6))\n",
    "industry_df['TARGET'].plot(kind='box')\n",
    "plt.title(\"Boxplot of Target Variable\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram to visualize the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "industry_df['TARGET'].hist(bins=30)\n",
    "plt.title(\"Histogram of Target Variable\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Statistical Methods to Detect Outliers**\n",
    "\n",
    "#### **a. Z-Score Method:**\n",
    "- If the target variable is **normally distributed**, use the **Z-score** method.\n",
    "- Values with a Z-score greater than a threshold (e.g., 3) are considered outliers.\n",
    "\n",
    "```python\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate Z-scores for the target variable\n",
    "z_scores_target = zscore(industry_df['TARGET'])\n",
    "\n",
    "# Filter out rows where the absolute Z-score is greater than 3\n",
    "industry_df_no_outliers = industry_df[abs(z_scores_target) < 3]\n",
    "```\n",
    "\n",
    "#### **b. IQR (Interquartile Range) Method:**\n",
    "- If the target variable is **not normally distributed**, the **IQR** method is more robust.\n",
    "- Outliers are defined as values outside the range [Q1 - 1.5*IQR, Q3 + 1.5*IQR].\n",
    "\n",
    "```python\n",
    "Q1 = industry_df['TARGET'].quantile(0.25)\n",
    "Q3 = industry_df['TARGET'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out rows where the target variable is outside the bounds\n",
    "industry_df_no_outliers = industry_df[(industry_df['TARGET'] >= lower_bound) & \n",
    "                                      (industry_df['TARGET'] <= upper_bound)]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Handling Outliers (Once Identified)**\n",
    "\n",
    "#### **a. Remove Outliers:**\n",
    "- If the outliers are likely **errors** or **irrelevant**, removing them is reasonable.\n",
    "\n",
    "```python\n",
    "industry_df_cleaned = industry_df[(industry_df['TARGET'] >= lower_bound) & \n",
    "                                  (industry_df['TARGET'] <= upper_bound)]\n",
    "```\n",
    "\n",
    "#### **b. Cap or Winsorize Outliers:**\n",
    "- If the outliers are **valid** but extreme, **capping** them at the upper and lower bounds can reduce their impact without losing data.\n",
    "\n",
    "```python\n",
    "industry_df['TARGET'] = industry_df['TARGET'].clip(lower=lower_bound, upper=upper_bound)\n",
    "```\n",
    "\n",
    "- **Winsorization** replaces extreme values with the nearest non-outlier value.\n",
    "\n",
    "#### **c. Transform the Target Variable:**\n",
    "- Apply **log transformation** or **Box-Cox transformation** to reduce the impact of outliers.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Apply log transformation (if the target variable has only positive values)\n",
    "industry_df['TARGET'] = np.log1p(industry_df['TARGET'])  # log(1 + x)\n",
    "```\n",
    "\n",
    "- For both positive and negative values, **Yeo-Johnson transformation** works well:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "industry_df['TARGET'] = pt.fit_transform(industry_df[['TARGET']])\n",
    "```\n",
    "\n",
    "#### **d. Impute Outliers:**\n",
    "- Replace outliers with a **median** or **mean** to reduce their influence.\n",
    "\n",
    "```python\n",
    "industry_df.loc[(industry_df['TARGET'] < lower_bound) | (industry_df['TARGET'] > upper_bound), 'TARGET'] = industry_df['TARGET'].median()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Model-Specific Handling of Outliers**\n",
    "\n",
    "Some machine learning models are more robust to outliers than others:\n",
    "\n",
    "- **Robust Models**: Algorithms like **Random Forest**, **Gradient Boosting**, or **XGBoost** are less sensitive to outliers.\n",
    "- **Linear Models**: Outliers can heavily influence linear regression, so handling outliers is critical.\n",
    "\n",
    "For robust linear regression:\n",
    "```python\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "X = industry_df.drop('TARGET', axis=1)\n",
    "y = industry_df['TARGET']\n",
    "\n",
    "# Robust regression that is less sensitive to outliers\n",
    "model = HuberRegressor()\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Practices:**\n",
    "1. **Understand the Cause of Outliers**:\n",
    "   - Are they due to data entry errors, unique events, or valid but extreme observations?\n",
    "2. **Avoid Blind Removal**:\n",
    "   - Removing outliers without understanding their significance can lead to loss of important information.\n",
    "3. **Document Your Process**:\n",
    "   - Keep track of how you handled outliers and why, especially in financial data where outliers may have significant implications."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
